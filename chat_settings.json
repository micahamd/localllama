{
    "developer": "ollama",
    "llm_model": "huihui_ai/qwen2.5-1m-abliterated:7b-instruct-q8_0",
    "embedding_model": "nomic-embed-text:latest",
    "temperature": 0.8,
    "context_size": 4000,
    "chunk_size": 128,
    "semantic_chunking": false,
    "include_chat": true,
    "show_image": false,
    "include_file": false,
    "system_prompt": "Respond honestly and factually at all times."
}